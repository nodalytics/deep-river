{
  "Binary classification": {
    "Dataset": {
      "Phishing": "Phishing websites.\n\nThis dataset contains features from web pages that are classified as phishing or not.\n\n    Name  Phishing                                                                                                     \n    Task  Binary classification                                                                                        \n Samples  1,250                                                                                                        \nFeatures  9                                                                                                            \n  Sparse  False                                                                                                        \n    Path  /Users/kulbach/Documents/environments/deep-river39/lib/python3.9/site-packages/river/datasets/phishing.csv.gz",
      "Bananas": "Bananas dataset.\n\nAn artificial dataset where instances belongs to several clusters with a banana shape.\nThere are two attributes that correspond to the x and y axis, respectively.\n\n    Name  Bananas                                                                                                 \n    Task  Binary classification                                                                                   \n Samples  5,300                                                                                                   \nFeatures  2                                                                                                       \n  Sparse  False                                                                                                   \n    Path  /Users/kulbach/Documents/environments/deep-river39/lib/python3.9/site-packages/river/datasets/banana.zip"
    },
    "Model": {
      "Logistic regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  LogisticRegression (\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.005\n      )\n    )\n    loss=Log (\n      weight_pos=1.\n      weight_neg=1.\n    )\n    l2=0.\n    l1=0.\n    intercept_init=0.\n    intercept_lr=Constant (\n      learning_rate=0.01\n    )\n    clip_gradient=1e+12\n    initializer=Zeros ()\n  )\n)",
      "Torch Logistic Regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Classifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Torch MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Classifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Torch LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RollingClassifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    window_size=20\n    append_predict=False\n  )\n)",
      "[baseline] Last Class": "NoChangeClassifier ()"
    }
  },
  "Multiclass classification": {
    "Dataset": {
      "ImageSegments": "Image segments classification.\n\nThis dataset contains features that describe image segments into 7 classes: brickface, sky,\nfoliage, cement, window, path, and grass.\n\n    Name  ImageSegments                                                                                                \n    Task  Multi-class classification                                                                                   \n Samples  2,310                                                                                                        \nFeatures  18                                                                                                           \n  Sparse  False                                                                                                        \n    Path  /Users/kulbach/Documents/environments/deep-river39/lib/python3.9/site-packages/river/datasets/segment.csv.zip",
      "Insects": "Insects dataset.\n\nThis dataset has different variants, which are:\n\n- abrupt_balanced\n- abrupt_imbalanced\n- gradual_balanced\n- gradual_imbalanced\n- incremental-abrupt_balanced\n- incremental-abrupt_imbalanced\n- incremental-reoccurring_balanced\n- incremental-reoccurring_imbalanced\n- incremental_balanced\n- incremental_imbalanced\n- out-of-control\n\nThe number of samples and the difficulty change from one variant to another. The number of\nclasses is always the same (6), except for the last variant (24).\n\n      Name  Insects                                                                                 \n      Task  Multi-class classification                                                              \n   Samples  52,848                                                                                  \n  Features  33                                                                                      \n   Classes  6                                                                                       \n    Sparse  False                                                                                   \n      Path  /Users/kulbach/river_data/Insects/INSECTS-abrupt_balanced_norm.arff                     \n       URL  http://sites.labic.icmc.usp.br/vsouza/repository/creme/INSECTS-abrupt_balanced_norm.arff\n      Size  15.66 MB                                                                                \nDownloaded  True                                                                                    \n   Variant  abrupt_balanced                                                                         \n\nParameters\n----------\n    variant\n        Indicates which variant of the dataset to load.",
      "Keystroke": "CMU keystroke dataset.\n\nUsers are tasked to type in a password. The task is to determine which user is typing in the\npassword.\n\nThe only difference with the original dataset is that the \"sessionIndex\" and \"rep\" attributes\nhave been dropped.\n\n      Name  Keystroke                                                     \n      Task  Multi-class classification                                    \n   Samples  20,400                                                        \n  Features  31                                                            \n    Sparse  False                                                         \n      Path  /Users/kulbach/river_data/Keystroke/DSL-StrongPasswordData.csv\n       URL  http://www.cs.cmu.edu/~keystroke/DSL-StrongPasswordData.csv   \n      Size  4.45 MB                                                       \nDownloaded  True                                                          "
    },
    "Model": {
      "Torch Logistic Regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Classifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Torch MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Classifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Torch LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RollingClassifier (\n    module=None\n    loss_fn=\"binary_cross_entropy\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    output_is_logit=True\n    is_class_incremental=True\n    device=\"cpu\"\n    seed=42\n    window_size=20\n    append_predict=False\n  )\n)",
      "[baseline] Last Class": "NoChangeClassifier ()"
    }
  },
  "Regression": {
    "Dataset": {
      "TrumpApproval": "Donald Trump approval ratings.\n\nThis dataset was obtained by reshaping the data used by FiveThirtyEight for analyzing Donald\nTrump's approval ratings. It contains 5 features, which are approval ratings collected by\n5 polling agencies. The target is the approval rating from FiveThirtyEight's model. The goal of\nthis task is to see if we can reproduce FiveThirtyEight's model.\n\n    Name  TrumpApproval                                                                                                      \n    Task  Regression                                                                                                         \n Samples  1,001                                                                                                              \nFeatures  6                                                                                                                  \n  Sparse  False                                                                                                              \n    Path  /Users/kulbach/Documents/environments/deep-river39/lib/python3.9/site-packages/river/datasets/trump_approval.csv.gz",
      "Friedman7k": "Sample from the stationary version of the Friedman dataset.\n\nThis sample contains 10k instances sampled from the Friedman generator.\n\n    Name  Friedman7k\n    Task  Regression\n Samples  7,000     \nFeatures  10        \n  Sparse  False     ",
      "FriedmanLEA10k": "Sample from the FriedmanLEA generator.\n\nThis sample contains 10k instances sampled from the Friedman generator and presents\nlocal-expanding abrupt concept drifts that locally affect the data and happen after\n2k, 5k, and 8k instances.\n\n    Name  FriedmanLEA10k\n    Task  Regression    \n Samples  10,000        \nFeatures  10            \n  Sparse  False         ",
      "FriedmanGSG10k": "Sample from the FriedmanGSG generator.\n\nThis sample contains 10k instances sampled from the Friedman generator and presents\nglobal and slow gradual concept drifts that affect the data and happen after\n3.5k and 7k instances. The transition window between different concepts has a length of\n1k instances.\n\n    Name  FriedmanGSG10k\n    Task  Regression    \n Samples  10,000        \nFeatures  10            \n  Sparse  False         "
    },
    "Model": {
      "Torch Linear Regression": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Regressor (\n    module=None\n    loss_fn=\"mse_loss\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "Torch MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  Regressor (\n    module=None\n    loss_fn=\"mse_loss\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "River MLP": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  MLPRegressor (\n    hidden_dims=(5,)\n    activations=(<class 'river.neural_net.activations.ReLU'>, <class 'river.neural_net.activations.ReLU'>, <class 'river.neural_net.activations.Identity'>)\n    loss=Squared ()\n    optimizer=SGD (\n      lr=Constant (\n        learning_rate=0.001\n      )\n    )\n    seed=42\n  )\n)",
      "Torch LSTM": "Pipeline (\n  StandardScaler (\n    with_std=True\n  ),\n  RollingRegressor (\n    module=None\n    loss_fn=\"mse_loss\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.005\n    window_size=20\n    append_predict=False\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "[baseline] Mean predictor": "StatisticRegressor (\n  statistic=Mean ()\n)"
    }
  }
}